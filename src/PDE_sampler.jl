


"""
    Posterior Struct

Initiates a structure of class Posterior to hold posterior samples

# Arguments

"""
mutable struct Posterior

  M
  gamma
  Î£Z
  Î£U
  A
  Ï€

end



function make_H(L, N, one_inds)
  H_tmp = zeros(L, N)
  H_tmp[diagind(H_tmp)] .= one_inds
  return H_tmp
end


"""
    update_M!(pars)

Used within DEtection() function with a spike-and-slab prior.
Updates ğŒ and ğšºáµ¤ from 

``ğš¯ ğ€ (ğ›—_{t^{(i)}}(t) âŠ— g(ğ›™(ğ¬)))' = ğŒ ğŸ(â‹…) + ğ›ˆ(ğ¬, t)`` 

where ``ğ›ˆ(ğ¬, t) âˆ¼ N_N(0, ğšºáµ¤)``and ``ğšºáµ¤ = diag(ÏƒÂ²áµ¤1, ..., ÏƒÂ²áµ¤N)``
"""
function update_M!(pars, model)

  samp_inds = model.inner_inds

  A0 = pars.Î£M
  sN = (length(samp_inds)-1) / 2
  N = length(samp_inds)

  Uprime = model.responseFunction([pars.State.State[model.responseNames[i]] for i in 1:length(model.responseNames)])

  # update Î£U and M
  for i in 1:model.N

    Uprimei = vec(Uprime[i, samp_inds])

   
    # g prior
    XÎ´ = pars.F[pars.gamma[i, :] .== 1, samp_inds]
    a0 = inv(XÎ´ * XÎ´') * XÎ´ * Uprimei
    A0 = N * inv(XÎ´ * XÎ´')
    A0inv = (1/N) * XÎ´ * XÎ´'

    AÎ´ = (N/(N+1)) * inv(XÎ´ * XÎ´')
    aÎ´ = AÎ´ * (XÎ´ * Uprimei + A0inv * a0)
    SN = (1 / 2) * (Uprimei'Uprimei + a0' * A0inv * a0 - aÎ´' * inv(AÎ´) * aÎ´)

    pars.Î£U[i, i] = rand(InverseGamma(sN, SN))



    pars.M[i, vec(pars.gamma[i, :] .!= 1)] .= 0
    pars.M[i, vec(pars.gamma[i, :] .== 1)] = rand(MvNormal(AÎ´ * (XÎ´ * Uprimei + A0inv * a0), pars.Î£U[i, i] .* Hermitian(AÎ´)))

  end

  return pars
end


"""
    update_gamma!(pars)

Used within DEtection() function with a spike-and-slab prior.
Updates gamma and pi from the spike-and-slab prior from

``p(ğŒâ¹ ğ›„) = p-slab(ğŒ áµ§)âˆâ±¼ p-spike(Mâ±¼)``

where ``p(Î³â±¼ = 1â¹ Ï€) = Ï€``, ``Ï€ âˆ¼ â„¬(a, b)``, ``p-slab(ğŒ áµ§) = N(ğŒ áµ§â¹ ğšáµ§, ğšºáµ¤ğ€áµ§)``, and ``ğ€áµ§ = cğˆ``.

"""
function update_gamma!(pars, model)

  samp_inds = StatsBase.sample(model.inner_inds, Int(length(model.inner_inds) - model.c), replace=false)

  # update spike Î´
  Î´tmp = pars.gamma
  sN = (length(samp_inds)) / 2
  N = length(samp_inds)
  g = N
  F = pars.F[:, samp_inds]


  for i in 1:model.N

    Uprime = vec(model.responseFunction([pars.State.State[model.responseNames[i]] for i in 1:length(model.responseNames)])[i, samp_inds])

    Î´order = sample(1:(model.D), model.D, replace=false)
    for j in Î´order

      Î´tmp1 = copy(Î´tmp[i, :])
      Î´tmp0 = copy(Î´tmp[i, :])
      Î´tmp1[j] = 1
      Î´tmp0[j] = 0
      XÎ´0 = F[Î´tmp0 .== 1, :]
      XÎ´1 = F[Î´tmp1 .== 1, :]

      # g-prior
      A00 = g * inv(XÎ´0*XÎ´0')
      A01 = g * inv(XÎ´1*XÎ´1')
      AÎ´0 = (g/(g+1)) * inv(XÎ´0 * XÎ´0')
      AÎ´1 = (g/(g+1)) * inv(XÎ´1 * XÎ´1')


      aÎ´0 = AÎ´0' * XÎ´0 * Uprime 
      aÎ´1 = AÎ´1' * XÎ´1 * Uprime
      SN0 = (1 / 2) * (Uprime' * Uprime - aÎ´0' * inv(AÎ´0) * aÎ´0)
      SN1 = (1 / 2) * (Uprime' * Uprime - aÎ´1' * inv(AÎ´1) * aÎ´1)

      R = (g+1)^(1/2) * (SN1 / SN0)^(sN)
      p = 1 / (1 + ((1 - pars.Ï€[i]) / pars.Ï€[i]) * R)

      Î´tmp[i, j] = rand(Binomial(1, p))

    end
  end

  pars.gamma = Î´tmp

  # update Ï€
  for i in 1:model.N
    pars.Ï€[i] = rand(Beta(1 + sum(pars.gamma[i, :]), 1 + sum(1 .- pars.gamma[i, :])))
  end

  return pars
end


"""
  update_Î£Z!(pars)

Used within DEtection() function with a spike-and-slab prior.
Updates ğšºz from 

``ğ³(ğ¬, t) = â„‹(ğ¬,t) ğš¯ ğ€ (ğ›—phi_{t^{(0)}}(t) âŠ— ğ›™(ğ¬))' + ğ›œ(ğ¬, t)``

where ``ğ›œ(ğ¬, t) âˆ¼ N_N(0, ğšºz)``, ``ğšºz = diag(ÏƒÂ²z1, ..., ÏƒÂ²zm)``, and ``ÏƒÂ²z âˆ¼ Half-t()``.

"""
function update_Î£Z!(pars, model)

  samp_inds = model.inner_inds

  sse_tmp = [model.Z[:, j] - model.H[j] * pars.State.State[pars.State.StateNames[1]][:, j] for j in samp_inds]
  sse_tmp = reduce(hcat, sse_tmp)
  for n in 1:model.N
    a_hat = (length(samp_inds) + pars.nu_Z) / 2
    b_hat = (0.5*(sse_tmp[n, :]'*sse_tmp[n, :])+pars.nu_Z[1]/pars.a_Z[n])[1]
    pars.Î£Z[n,n] = rand(InverseGamma(a_hat, b_hat))
  end

  for n in 1:model.N
    a_hat = (pars.nu_Z + 1) / 2
    b_hat = (pars.nu_Z / pars.Î£Z[n]) + (1 / pars.A_Z[n]^2)
    pars.a_Z[n] = rand(InverseGamma(a_hat, b_hat))
  end

  return pars
end


"""
  Î”L(z, H, Ïˆ, gÏˆ, Ï•, Ï•_t, Î˜, Î£Zinv, Î£Uinv, A, M, fcurr, fprime)

Used within DEtection() function.
Calculates the gradient of the log likelihood.
"""
function Î”L(z, H, Ïˆ, gÏˆ, Ï•, Ï•_t, Î˜, Î£Zinv, Î£Uinv, A, M, fcurr, fprime::Matrix{Float64})

  B0 = Ï• âŠ— Ïˆ
  Bt = Ï•_t âŠ— gÏˆ

  Î”L = -Î˜ * H' * Î£Zinv * z * B0' +
        Î˜ * H' * Î£Zinv * H * Î˜ * A * B0 * B0' +
        Î˜ * Î£Uinv * Î˜ * A * Bt * Bt' -
        Î˜ * Î£Uinv * M * fcurr * Bt' -
        Bt' * A' * Î˜' * Î£Uinv * M * fprime +
        (fcurr' * M' * Î£Uinv * M) * fprime

  return Î”L

end

function Î”L(z, H, Ïˆ, gÏˆ, Ï•, Ï•_t, Î˜, Î£Zinv, Î£Uinv, A, M, fcurr, fprime::Array{Float64, 3})

  B0 = Ï• âŠ— Ïˆ
  Bt = Ï•_t âŠ— gÏˆ

  Î”L = -Î˜ * H' * Î£Zinv * z * B0' +
        Î˜ * H' * Î£Zinv * H * Î˜ * A * B0 * B0' +
        Î˜ * Î£Uinv * Î˜ * A * Bt * Bt' -
        Î˜ * Î£Uinv * M * fcurr * Bt' -
        reduce(vcat, [Bt' * A' * Î˜' * Î£Uinv * M * fprime[:,:,i] - (fcurr' * M' * Î£Uinv * M) * fprime[:,:,i] for i in 1:size(fprime,3)])

  return Î”L

end



"""
    update_A!(pars)

Used within DEtection() function with a spike-and-slab prior.
Updates ğ€ with the elastic net prior (Li 2010) from

``ğ³(ğ¬, t) = â„‹(ğ¬,t) ğš¯ ğ€ (ğ›—phi_{t^{(0)}}(t) âŠ— ğ›™(ğ¬))' + ğ›œ(ğ¬, t)``

``ğš¯ ğ€ (ğ›—_{t^{(i)}}(t) âŠ— g(ğ›™(ğ¬)))' = ğŒ ğŸ(â‹…) + ğ›ˆ(ğ¬, t)`` 

``p(ğ€) âˆ exp{-Î»â‚â€–ğ€â€–â‚ - Î»â‚‚â€–ğ€â€–â‚‚Â²}``

using Stochastic Gradient Desent with a Constant Learning Rate (Mandt 2016).
Î»â‚ and Î»â‚‚ are set to 1/100.

"""
function update_A!(pars, model)

  samp_space, samp_time, samp_inds = sample_inds(model.SpaceStep, model.TimeStep, model.batchSpace, model.batchTime, model.bufferSpace, model.bufferTime)
  
  z = model.Z[:, samp_inds] # if an error occurs with 1D vs 2D space, it is here
  h = model.H[samp_inds]
  Ïˆ = model.Basis.SpaceDerivative["Psi"][samp_space, :]
  gÏˆ = model.responseFunction([model.Basis.SpaceDerivative[model.Î¨names[i]] for i in 1:length(model.Î¨names)])[samp_space, :]
  Ï• = model.Basis.TimeDerivative[model.Basis.TimeNames[1]][samp_time, :]
  Ï•_t = model.Basis.TimeDerivative[model.Basis.TimeNames[end]][samp_time, :]
  Î˜ = model.Î˜
  Î£Zinv = inv(pars.Î£Z)
  Î£Uinv = inv(pars.Î£U)
  A = pars.A
  M = pars.M

  fcurr = pars.F[:, samp_inds]
  fprime = create_âˆ‡Î›(model.âˆ‡Î›, A, model.Basis, samp_space, samp_time, samp_inds, model.Î›SpaceNames, model.Î›TimeNames, model.X)
  dq = [Î”L(z[:, i], h[i], Ïˆ[i, :], gÏˆ[i, :], Ï•[i, :], Ï•_t[i, :], Î˜, Î£Zinv, Î£Uinv, A, M, fcurr[:, i], fprime[i]) for i in 1:length(samp_inds)]

  scale_el = 1 / 100
  dq = mean(dq) + (1 / (model.S * model.T)) * (scale_el * sign.(A) + 2 * scale_el * A)
  
  pars.A = A - dq .* model.learning_rate

  # save updated state information
  pars.sample_inds = samp_inds
  pars.State = construct_state(pars.A, model.Basis, model.Î˜)
  pars.F = create_Î›(model.Î›, pars.A, model.Basis, model.Î›SpaceNames, model.Î›TimeNames, model.X)
  pars.Fprime = fprime

  return pars
end


"""
    DEtection(Y, SpaceStep, TimeStep, Î½S, Î½T, bufferSpace, bufferTime, batchSpace, batchTime, learning_rate, v0, v1, Î›, Î›names)

DEtection sampler function. Can accept missing values in the input data argument.
Returns the model, parameters, and posterior values.
The model are the model settings.
The parameters are the final value of the parameters in from the sampler.
The posterior are the saved posterior values.

Consider the function ``U_t = M(U, U_x, U_y, U_{xy}, ...)``.
DEtection() is used to determine ``M`` given a library of potential values, `Î›(U, âˆ‚U)`, to search over. 
Within the function, partial derivatives are denoted as ``Î”U_t, Î”U_x, Î”U_y, Î”U_xx, , Î”U_xy, ...``, so a potential function could be

```example 
function Î›(U, âˆ‚U){
  u = U[1]
  u_x = âˆ‚U[1]
  u_y = âˆ‚U[2]

  return [u, u_x, u_y, u*u_x, u*u_y]
}
```

To make the function identify the correct partial derivatives, the argument that are passed into `âˆ‚U`, `Î›names`, are required.
For the example above, `Î›names = [Î”U_x, Î”U_y]` because the function `Î›` uses the partial derivatives ``U_x`` and ``U_t``.

If you want to add covariates to the function, a possible `Î›(U, âˆ‚U, X)` is

```example 
function Î›(U, âˆ‚U, X){
  u = U[1]
  u_x = âˆ‚U[1]
  u_y = âˆ‚U[2]
  x1 = X[1]
  x2 = X[2]

  return [u, u_x, u_y, u*u_x, u*u_y, x1, x2, u*x1, u_x*x2]
}
```

where `Î›names = [Î”U_x, Î”U_y]`.

# Required Arguments (in order)
- `Y`: Input data. Needs to be Array{Float64, 3} or Array{Union{Missing, Float64}, 3} where the dimensions are Space, Time, Components
- `SpaceStep`: of type StepRangeLen (range function). For example, range(-1, 1, step = 0.1) for 1 dimension and [range(-1, 1, step = 0.1), range(-1, 1, step = 0.1)] for 2.
- `TimeStep`: of type StepRangeLen (range function). For example, range(-1, 1, step = 0.1).
- `Î½S::Int` or `Î½S::Vector{Int}`: Number of spatial basis functions. 
- `Î½T::Int`: Number of temporal basis functions
- `batchSpace::Int`: 
- `batchTime::Int`: 
- `learning_rate::Float64`: 
- `v0::Float64`: 
- `v1::Float64`: 
- `Î›::Function`: 
- `Î›names::Vector{String}`: 

# Optional Arguments
- `response` = "Î”U_t": Order of the temporal derivative (default first order). Use "Î”U_tt" for second and so on.
- `degree` = 4: Degree of the B-spline. Must be at least one order higher than the highest order partial derivative.
- `orderTime` = 1: Order of the highest order temporal derivative (default âˆ‚U_t)
- `orderSpace` = 3: Order of the highest order spatial derivative (default âˆ‚U_xxx and âˆ‚U_yyy)
- `latent_dim` = size(Y, 3): Dimension of the latent space. Default is same as data dimension.
- `covariates` = nothing: Additional covariates.
- `nits` = 2000: Number of samples for the Gibbs sampler.
- `burnin` = nits / 2: Number of samples to discard as burnin (default is half of `nits`).
- `learning_rate_end` = learning_rate: End learning rate (default is same as initial learning rate).

"""
function DEtection(Y::Array{Float64,3},
  SpaceStep::Vector,
  TimeStep::Vector,
  Î½S::Int,
  Î½T::Int,
  batchSpace::Int,
  batchTime::Int,
  learning_rate::Float64,
  beta::Float64,
  Î›::Function,
  âˆ‡Î›::Function,
  Î›SpaceNames::Vector{String},
  Î›TimeNames::Vector{String};
  bufferSpace::Int = 1,
  bufferTime::Int = 1,
  response=nothing, responsenames=nothing, degree=4, orderTime=1, orderSpace=3, latent_dim=size(Y, 3), covariates=nothing, nits=2000, burnin=nits / 2, learning_rate_end=learning_rate)

  pars, model = create_pars(Y, SpaceStep, TimeStep, Î½S, Î½T, batchSpace, batchTime, learning_rate, beta, Î›, âˆ‡Î›, Î›SpaceNames, Î›TimeNames, bufferSpace = bufferSpace, bufferTime = bufferTime, response=response, responsenames=responsenames, degree=degree, orderTime=orderTime, orderSpace=orderSpace, latent_dim=latent_dim, covariates=covariates)

  # decaying learning rate
  keep_samps = Int(nits - burnin)
  n_change = log10(learning_rate / learning_rate_end)
  if n_change == 0
    change_times = 0.0
  else
    change_times = floor.(collect(range(1, stop=burnin, length=Int((n_change + 1)))))[2:end]
  end

  M_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  gamma_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  Î£Z_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  Î£U_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  A_post = Array{Float64}(undef, model.N, size(pars.A)[2], keep_samps)
  Ï€_post = Array{Float64}(undef, model.N, keep_samps)


  @showprogress 1 "Burnin..." for i in 1:burnin

    pars = update_gamma!(pars, model)
    pars = update_M!(pars, model)
    pars = update_Î£Z!(pars, model)
    pars = update_A!(pars, model)

    if i in change_times
      raise_pow = findall(change_times .== i)[1]
      model.learning_rate = round(learning_rate * 10.0^(-raise_pow), digits = raise_pow+6)
    end

  end

  @showprogress 1 "Sampling..." for i in 1:keep_samps

    pars = update_gamma!(pars, model)
    pars = update_M!(pars, model)
    pars = update_Î£Z!(pars, model)
    pars = update_A!(pars, model)

    M_post[:, :, i] = pars.M
    gamma_post[:, :, i] = pars.gamma
    Î£Z_post[:, :, i] = pars.Î£Z
    Î£U_post[:, :, i] = pars.Î£U
    A_post[:, :, i] = pars.A
    Ï€_post[:, i] = pars.Ï€

  end

  posterior = Posterior(M_post, gamma_post, Î£Z_post, Î£U_post, A_post, Ï€_post)

  return model, pars, posterior

end # 1 spatial dimension DEtection

function DEtection(Y::Array{Float64,3},
  SpaceStep::Vector,
  TimeStep::Vector,
  Î½S::Vector{Int},
  Î½T::Int,
  batchSpace::Int,
  batchTime::Int,
  learning_rate::Vector{Float64},
  beta::Float64,
  Î›::Function,
  âˆ‡Î›::Function,
  Î›SpaceNames::Vector{String},
  Î›TimeNames::Vector{String};
  bufferSpace::Vector{Int} = [1, 1],
  bufferTime::Int = 1,
  response=nothing, responsenames=nothing, degree=4, orderTime=1, orderSpace=3, latent_dim=size(Y, 3), covariates=nothing, nits=2000, burnin=nits / 2, learning_rate_end=learning_rate)

  if typeof(learning_rate) != Vector{Float64}
    learning_rate = learning_rate * ones(latent_dim)
  end

  pars, model = create_pars(Y, SpaceStep, TimeStep, Î½S, Î½T, batchSpace, batchTime, learning_rate, beta, Î›, âˆ‡Î›, Î›SpaceNames, Î›TimeNames, bufferSpace = bufferSpace, bufferTime = bufferTime, response=response, responsenames=responsenames, degree=degree, orderTime=orderTime, orderSpace=orderSpace, latent_dim=latent_dim, covariates=covariates)
  # pars, model = create_pars(Y, SpaceStep, TimeStep, Î½S, Î½T, bufferSpace, bufferTime, batchSpace, batchTime, learning_rate, c, Î›, âˆ‡Î›, Î›SpaceNames, Î›TimeNames, response=response, responsenames=responsenames, degree=degree, orderTime=orderTime, orderSpace=orderSpace, latent_dim=latent_dim, covariates=covariates)

  # decaying learning rate
  keep_samps = Int(nits - burnin)
  n_change = log10.(learning_rate ./ learning_rate_end)
  # if n_change .== 0
  #   change_times = 0.0
  # else
  #   change_times = floor.(collect(range(1, stop=burnin, length=Int((n_change + 1)))))[2:end]
  # end
  change_times = 0

  M_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  gamma_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  Î£Z_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  Î£U_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  A_post = Array{Float64}(undef, model.N, size(pars.A)[2], keep_samps)
  Ï€_post = Array{Float64}(undef, model.N, keep_samps)


  @showprogress 1 "Burnin..." for i in 1:burnin

    pars = update_gamma!(pars, model)
    pars = update_M!(pars, model)
    pars = update_Î£Z!(pars, model)
    pars = update_A!(pars, model)

    if i in change_times
      raise_pow = findall(change_times .== i)[1]
      model.learning_rate = round(learning_rate * 10.0^(-raise_pow), digits = raise_pow+6)
    end

  end

  @showprogress 1 "Sampling..." for i in 1:keep_samps

    pars = update_gamma!(pars, model)
    pars = update_M!(pars, model)
    pars = update_Î£Z!(pars, model)
    pars = update_A!(pars, model)

    M_post[:, :, i] = pars.M
    gamma_post[:, :, i] = pars.gamma
    Î£Z_post[:, :, i] = pars.Î£Z
    Î£U_post[:, :, i] = pars.Î£U
    A_post[:, :, i] = pars.A
    Ï€_post[:, i] = pars.Ï€

  end

  posterior = Posterior(M_post, gamma_post, Î£Z_post, Î£U_post, A_post, Ï€_post)

  return model, pars, posterior

end # 2 spatial dimensions DEtection

function DEtection(Y::Array{Union{Missing,Float64},3},
  SpaceStep::Vector,
  TimeStep::Vector,
  Î½S::Int,
  Î½T::Int,
  batchSpace::Int,
  batchTime::Int,
  learning_rate::Float64,
  beta::Float64,
  Î›::Function,
  âˆ‡Î›::Function,
  Î›SpaceNames::Vector{String},
  Î›TimeNames::Vector{String};
  bufferSpace::Int = 1,
  bufferTime::Int = 1,
  response=nothing, responsenames=nothing, degree=4, orderTime=1, orderSpace=3, latent_dim=size(Y, 3), covariates=nothing, nits=2000, burnin=nits / 2, learning_rate_end=learning_rate)

  pars, model = create_pars(Y, SpaceStep, TimeStep, Î½S, Î½T, batchSpace, batchTime, learning_rate, beta, Î›, âˆ‡Î›, Î›SpaceNames, Î›TimeNames, bufferSpace = bufferSpace, bufferTime = bufferTime, response=response, responsenames=responsenames, degree=degree, orderTime=orderTime, orderSpace=orderSpace, latent_dim=latent_dim, covariates=covariates)
  # pars, model = create_pars(Y, SpaceStep, TimeStep, Î½S, Î½T, bufferSpace, bufferTime, batchSpace, batchTime, learning_rate, c, Î›, âˆ‡Î›, Î›SpaceNames, Î›TimeNames, response=response, responsenames=responsenames, degree=degree, orderTime=orderTime, orderSpace=orderSpace, latent_dim=latent_dim, covariates=covariates)

  # decaying learning rate
  keep_samps = Int(nits - burnin)
  n_change = log10(learning_rate / learning_rate_end)
  if n_change == 0
    change_times = 0.0
  else
    change_times = floor.(collect(range(1, stop=burnin, length=Int((n_change + 1)))))[2:end]
  end

  M_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  gamma_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  Î£Z_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  Î£U_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  A_post = Array{Float64}(undef, model.N, size(pars.A)[2], keep_samps)
  Ï€_post = Array{Float64}(undef, model.N, keep_samps)


  @showprogress 1 "Burnin..." for i in 1:burnin

    pars = update_gamma!(pars, model)
    pars = update_M!(pars, model)
    pars = update_Î£Z!(pars, model)
    pars = update_A!(pars, model)

    if i in change_times
      raise_pow = findall(change_times .== i)[1]
      model.learning_rate = round(learning_rate * 10.0^(-raise_pow), digits = raise_pow+6)
    end

  end

  @showprogress 1 "Sampling..." for i in 1:keep_samps

    pars = update_gamma!(pars, model)
    pars = update_M!(pars, model)
    pars = update_Î£Z!(pars, model)
    pars = update_A!(pars, model)

    M_post[:, :, i] = pars.M
    gamma_post[:, :, i] = pars.gamma
    Î£Z_post[:, :, i] = pars.Î£Z
    Î£U_post[:, :, i] = pars.Î£U
    A_post[:, :, i] = pars.A
    Ï€_post[:, i] = pars.Ï€

  end

  posterior = Posterior(M_post, gamma_post, Î£Z_post, Î£U_post, A_post, Ï€_post)

  return model, pars, posterior

end # 1 spatial dimension DEtection - missing values

function DEtection(Y::Array{Union{Missing,Float64},3},
  SpaceStep::Vector,
  TimeStep::Vector,
  Î½S::Vector{Int},
  Î½T::Int,
  batchSpace::Int,
  batchTime::Int,
  learning_rate::Vector{Float64},
  beta::Float64,
  Î›::Function,
  âˆ‡Î›::Function,
  Î›SpaceNames::Vector{String},
  Î›TimeNames::Vector{String};
  bufferSpace::Vector{Int} = [1,1],
  bufferTime::Int = 1,
  response=nothing, responsenames=nothing, degree=4, orderTime=1, orderSpace=3, latent_dim=size(Y, 3), covariates=nothing, nits=2000, burnin=nits / 2, learning_rate_end=learning_rate)

  if typeof(learning_rate) != Vector{Float64}
    learning_rate = learning_rate * ones(latent_dim)
  end

  pars, model = create_pars(Y, SpaceStep, TimeStep, Î½S, Î½T, batchSpace, batchTime, learning_rate, beta, Î›, âˆ‡Î›, Î›SpaceNames, Î›TimeNames, bufferSpace = bufferSpace, bufferTime = bufferTime, response=response, responsenames=responsenames, degree=degree, orderTime=orderTime, orderSpace=orderSpace, latent_dim=latent_dim, covariates=covariates)
  # pars, model = create_pars(Y, SpaceStep, TimeStep, Î½S, Î½T, bufferSpace, bufferTime, batchSpace, batchTime, learning_rate, c, Î›, âˆ‡Î›, Î›SpaceNames, Î›TimeNames, response=response, responsenames=responsenames, degree=degree, orderTime=orderTime, orderSpace=orderSpace, latent_dim=latent_dim, covariates=covariates)

  # decaying learning rate
  keep_samps = Int(nits - burnin)
  n_change = log10(learning_rate / learning_rate_end)
  if n_change == 0
    change_times = 0.0
  else
    change_times = floor.(collect(range(1, stop=burnin, length=Int((n_change + 1)))))[2:end]
  end

  M_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  gamma_post = Array{Float64}(undef, model.N, model.D, keep_samps)
  Î£Z_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  Î£U_post = Array{Float64}(undef, model.N, model.N, keep_samps)
  A_post = Array{Float64}(undef, model.N, size(pars.A)[2], keep_samps)
  Ï€_post = Array{Float64}(undef, model.N, keep_samps)


  @showprogress 1 "Burnin..." for i in 1:burnin

    pars = update_gamma!(pars, model)
    pars = update_M!(pars, model)
    pars = update_Î£Z!(pars, model)
    pars = update_A!(pars, model)

    if i in change_times
      raise_pow = findall(change_times .== i)[1]
      model.learning_rate = round(learning_rate * 10.0^(-raise_pow), digits = raise_pow+6)
    end

  end

  @showprogress 1 "Sampling..." for i in 1:keep_samps

    pars = update_gamma!(pars, model)
    pars = update_M!(pars, model)
    pars = update_Î£Z!(pars, model)
    pars = update_A!(pars, model)

    M_post[:, :, i] = pars.M
    gamma_post[:, :, i] = pars.gamma
    Î£Z_post[:, :, i] = pars.Î£Z
    Î£U_post[:, :, i] = pars.Î£U
    A_post[:, :, i] = pars.A
    Ï€_post[:, i] = pars.Ï€

  end

  posterior = Posterior(M_post, gamma_post, Î£Z_post, Î£U_post, A_post, Ï€_post)

  return model, pars, posterior

end # 2 spatial dimensions DEtection - missing values
