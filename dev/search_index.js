var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [BayesianDiscovery]","category":"page"},{"location":"api/#BayesianDiscovery.BayesianDiscovery","page":"API","title":"BayesianDiscovery.BayesianDiscovery","text":"BayesianDiscovery\n\nHere is my package.\n\n\n\n\n\n","category":"module"},{"location":"api/#BayesianDiscovery.Posterior","page":"API","title":"BayesianDiscovery.Posterior","text":"Posterior Struct\n\nInitiates a structure of class Posterior to hold posterior samples\n\nArguments\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesianDiscovery.DEtection-Tuple{Array{Float64, 3}, Vector, Vector, Int64, Int64, Int64, Int64, Float64, Float64, Function, Function, Vector{String}, Vector{String}}","page":"API","title":"BayesianDiscovery.DEtection","text":"DEtection(Y, SpaceStep, TimeStep, νS, νT, bufferSpace, bufferTime, batchSpace, batchTime, learning_rate, v0, v1, Λ, Λnames)\n\nDEtection sampler function. Can accept missing values in the input data argument. Returns the model, parameters, and posterior values. The model are the model settings. The parameters are the final value of the parameters in from the sampler. The posterior are the saved posterior values.\n\nConsider the function U_t = M(U U_x U_y U_xy ). DEtection() is used to determine M given a library of potential values, Λ(U, ∂U), to search over.  Within the function, partial derivatives are denoted as ΔU_t ΔU_x ΔU_y ΔU_xx  ΔU_xy , so a potential function could be\n\nfunction Λ(U, ∂U){\n  u = U[1]\n  u_x = ∂U[1]\n  u_y = ∂U[2]\n\n  return [u, u_x, u_y, u*u_x, u*u_y]\n}\n\nTo make the function identify the correct partial derivatives, the argument that are passed into ∂U, Λnames, are required. For the example above, Λnames = [ΔU_x, ΔU_y] because the function Λ uses the partial derivatives U_x and U_t.\n\nIf you want to add covariates to the function, a possible Λ(U, ∂U, X) is\n\nfunction Λ(U, ∂U, X){\n  u = U[1]\n  u_x = ∂U[1]\n  u_y = ∂U[2]\n  x1 = X[1]\n  x2 = X[2]\n\n  return [u, u_x, u_y, u*u_x, u*u_y, x1, x2, u*x1, u_x*x2]\n}\n\nwhere Λnames = [ΔU_x, ΔU_y].\n\nRequired Arguments (in order)\n\nY: Input data. Needs to be Array{Float64, 3} or Array{Union{Missing, Float64}, 3} where the dimensions are Space, Time, Components\nSpaceStep: of type StepRangeLen (range function). For example, range(-1, 1, step = 0.1) for 1 dimension and [range(-1, 1, step = 0.1), range(-1, 1, step = 0.1)] for 2.\nTimeStep: of type StepRangeLen (range function). For example, range(-1, 1, step = 0.1).\nνS::Int or νS::Vector{Int}: Number of spatial basis functions. \nνT::Int: Number of temporal basis functions\nbatchSpace::Int: \nbatchTime::Int: \nlearning_rate::Float64: \nv0::Float64: \nv1::Float64: \nΛ::Function: \nΛnames::Vector{String}: \n\nOptional Arguments\n\nresponse = \"ΔUt\": Order of the temporal derivative (default first order). Use \"ΔUtt\" for second and so on.\ndegree = 4: Degree of the B-spline. Must be at least one order higher than the highest order partial derivative.\norderTime = 1: Order of the highest order temporal derivative (default ∂U_t)\norderSpace = 3: Order of the highest order spatial derivative (default ∂Uxxx and ∂Uyyy)\nlatent_dim = size(Y, 3): Dimension of the latent space. Default is same as data dimension.\ncovariates = nothing: Additional covariates.\nnits = 2000: Number of samples for the Gibbs sampler.\nburnin = nits / 2: Number of samples to discard as burnin (default is half of nits).\nlearning_rate_end = learning_rate: End learning rate (default is same as initial learning rate).\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.bspline-NTuple{4, Any}","page":"API","title":"BayesianDiscovery.bspline","text":"bspline(x, knot_locs, degree, derivative)\n\nCreates a matrix of B-Splines evaluated at each x with specified knot locations and degree. Dimension is (length(x), length(xknotlocs)). Returns the basis matrix and the derivative of the basis matrix.\n\nArguments\n\nx: data\nknot_locs: knot locations\ndegree: degree of the B-Spline\nderivative: order of the derivative for Psi_x\n\nExamples\n\nx = 1:1:30\nknot_locs = 5:5:25\ndegree = 3\nderivative = 1\n\nPsi, Psi_x = bspline(x, knot_locs, degree, derivative)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.create_pars-Tuple{Array{Float64, 3}, Vector, Vector, Vector{Int64}, Int64, Int64, Int64, Vector{Float64}, Float64, Function, Function, Vector{String}, Vector{String}}","page":"API","title":"BayesianDiscovery.create_pars","text":"create_pars()\n\nConstructs the parameter and model classes.\n\nArguments\n\nY::Array{Float64, 3}: Space x Time x Component data array\nSpaceStep::Vector{StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}}}: Vector of spatial locations [x, y]\nTimeStep::StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}}: Time samples\nνS::Vector{Int32}: number of spatial basis functions [x, y]\nνT::Int: number of temporal basis functions\nbufferSpace::Vector{Int}: spatial buffer [x, y]\nbufferTime::Int: temporal buffer\nbatchSpace::Int: batch size for space [x, y]\nbatchTime::Int: batch size for time\nlearning_rate::Float64: learning rate\nv0::Float64: ssvs not included variance\nv1::Float64: ssvs included variance\nΛ::Function: function library\nΛnames::Vector{String}: names of arguments in function library\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.fold3-NTuple{4, Any}","page":"API","title":"BayesianDiscovery.fold3","text":"fold3(Y)\n\nUsed to construct a tensor from the mode-3 matrix Y.\n\nExamples\n\nY3 = unfold3(Y) I = size(Y, 1) J = size(Y, 2) K = size(Y, 3)\n\nY = fold3(Y3, I, J, K)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.spatial_bspline-NTuple{7, Any}","page":"API","title":"BayesianDiscovery.spatial_bspline","text":"spatial_bspline(x, y, x_knot_locs, y_knot_locs, degree)\n\nCreates a matrix of B-Splines evaluated at each x and y with specified knot locations and degree. Dimension is (length(x)length(y), length(xknotlocs)length(yknotlocs)). Returns the basis matrix and the derivative of the basis matrix.\n\nArguments\n\nx: data in the x direction\ny: data in the x direction\nxknotlocs: knot locations for x\nyknotlocs: knot locations for y\ndegree: degree of the B-Spline\n\nExamples\n\nx = 1:1:30\ny = 1:1:30\nx_knot_locs = 5:5:25\ny_knot_locs = 5:5:25\ndegree = 3\n\nPsi, Psi_x, Psi_y, Psi_xy = spatial_bspline(x, y, x_knot_locs, y_knot_locs, degree)\n\n# plot the functions\nPlots.pyplot()\ncontour(x, y, reshape(Psi, length(x), length(y)), fill = true)\ncontour(x, y, reshape(Psi_x, length(x), length(y)), fill = true)\ncontour(x, y, reshape(Psi_y, length(x), length(y)), fill = true)\ncontour(x, y, reshape(Psi_xy, length(x), length(y)), fill = true)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.tensor_mult-NTuple{4, Any}","page":"API","title":"BayesianDiscovery.tensor_mult","text":"tensor_mult(G, A, B, C)\n\nUsed to multiply a tensor G ∈ R(I1, I2, I3) with matrices A ∈ R(P, I1), B ∈ R(Q, I2), C ∈ R(R, I3)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.unfold3-Tuple{Array{Float64, 3}}","page":"API","title":"BayesianDiscovery.unfold3","text":"unfold3(Y)\n\nUsed to get the mode-3 matrix of the tensor Y.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.update_A!-Tuple{Any, Any}","page":"API","title":"BayesianDiscovery.update_A!","text":"update_A!(pars)\n\nUsed within DEtection() function with a spike-and-slab prior. Updates 𝐀 with the elastic net prior (Li 2010) from\n\n𝐳(𝐬 t) = ℋ(𝐬t) 𝚯 𝐀 (𝛗phi_t^(0)(t)  𝛙(𝐬)) + 𝛜(𝐬 t)\n\n𝚯 𝐀 (𝛗_t^(i)(t)  g(𝛙(𝐬))) = 𝐌 𝐟() + 𝛈(𝐬 t) \n\np(𝐀)  exp-λ₁𝐀₁ - λ₂𝐀₂²\n\nusing Stochastic Gradient Desent with a Constant Learning Rate (Mandt 2016). λ₁ and λ₂ are set to 1/100.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.update_M!-Tuple{Any, Any}","page":"API","title":"BayesianDiscovery.update_M!","text":"update_M!(pars)\n\nUsed within DEtection() function with a spike-and-slab prior. Updates 𝐌 and 𝚺ᵤ from \n\n𝚯 𝐀 (𝛗_t^(i)(t)  g(𝛙(𝐬))) = 𝐌 𝐟() + 𝛈(𝐬 t) \n\nwhere 𝛈(𝐬 t)  N_N(0 𝚺ᵤ)and 𝚺ᵤ = diag(σ²ᵤ1  σ²ᵤN)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.update_gamma!-Tuple{Any, Any}","page":"API","title":"BayesianDiscovery.update_gamma!","text":"update_gamma!(pars)\n\nUsed within DEtection() function with a spike-and-slab prior. Updates gamma and pi from the spike-and-slab prior from\n\np(𝐌 𝛄) = p-slab(𝐌 ᵧ)ⱼ p-spike(Mⱼ)\n\nwhere p(γⱼ = 1 π) = π, π  ℬ(a b), p-slab(𝐌 ᵧ) = N(𝐌 ᵧ 𝐚ᵧ 𝚺ᵤ𝐀ᵧ), and 𝐀ᵧ = c𝐈.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.update_ΣZ!-Tuple{Any, Any}","page":"API","title":"BayesianDiscovery.update_ΣZ!","text":"update_ΣZ!(pars)\n\nUsed within DEtection() function with a spike-and-slab prior. Updates 𝚺z from \n\n𝐳(𝐬 t) = ℋ(𝐬t) 𝚯 𝐀 (𝛗phi_t^(0)(t)  𝛙(𝐬)) + 𝛜(𝐬 t)\n\nwhere 𝛜(𝐬 t)  N_N(0 𝚺z), 𝚺z = diag(σ²z1  σ²zm), and σ²z  Half-t().\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.ΔL-Tuple{Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Matrix{Float64}}","page":"API","title":"BayesianDiscovery.ΔL","text":"ΔL(z, H, ψ, gψ, ϕ, ϕ_t, Θ, ΣZinv, ΣUinv, A, M, fcurr, fprime)\n\nUsed within DEtection() function. Calculates the gradient of the log likelihood.\n\n\n\n\n\n","category":"method"},{"location":"heat/","page":"Heat Equation","title":"Heat Equation","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"heat/#Heat-Example","page":"Heat Equation","title":"Heat Example","text":"","category":"section"},{"location":"heat/","page":"Heat Equation","title":"Heat Equation","text":"#TODO: Finish example docs","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"featurelibrary/#Feature-Library-Inputs","page":"Feature Library","title":"Feature Library Inputs","text":"","category":"section"},{"location":"featurelibrary/#Feature-Library","page":"Feature Library","title":"Feature Library","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"Properly defining the feature library to work with the DEtection() function is challenging. There are two input functions for the feature library, Λ and ∇Λ. Λ is the actual library and ∇Λ is the derivative of Λ (note, this could be replaced with automatic differention, but AD is slow in this case). Each function must take 3 parameters, A Ψ Φ where A is a matrix of the basis coefficients, Ψ = ψ ψ_x ψ_xx  is a vector of spatial basis functions and Φ = ϕ ϕ_t ϕ_tt  is a vector of temporal basis functions. The surface and its derivatives are then reconstructed as u = A * (ϕ  ψ), u_x = A * (ϕ  ψ_x), u_t = A * (ϕ_t  ψ), and so on, within the function. The first function, Λ, must return a vector of u and all of the functions in the feature library such as,","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function Λ(A, Ψ, Φ)\n    \n  ψ = Ψ[1] # no spatial derivatice\n  ψ_x = Ψ[2] # first order spatial derivative in the x direction\n  ψ_xx = Ψ[3] # second order spatial derivative in the x direction\n  ψ_xxx = Ψ[4] # third order spatial derivative in the x direction\n\n  ϕ = Φ[1] # no temporal derivatice\n\n  u = A * (ϕ ⊗ ψ)' # base process\n  u_x = A * (ϕ ⊗ ψ_x)' # first order spatial derivative of the process in the x direction\n  u_xx = A * (ϕ ⊗ ψ_xx)' # second order spatial derivative of the process in the x direction\n  u_xxx = A * (ϕ ⊗ ψ_xxx)' # third order spatial derivative of the process in the x direction\n\n  return [u, u.^2, u.^3,\n    u_x, u .* u_x, u.^2 .* u_x, u.^3 .* u_x,\n    u_xx, u .* u_xx, u.^2 .* u_xx, u.^3 .* u_xx,\n    u_xxx, u .* u_xxx, u.^2 .* u_xxx, u.^3 .* u_xxx] # this is the feature library\n\nend","category":"page"},{"location":"featurelibrary/#Feature-Library-Derivative","page":"Feature Library","title":"Feature Library Derivative","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"The second function, Λ, is slightly more complicated. It requires the same inputs, however the output is the derivative of the feature library with respect to the matrix A. We have included some helper function, such as BayesianDiscovery.dU(A, ϕ, ψ) or BayesianDiscovery.dU_x(A, ϕ, ψ_x), but you can write your own functions if you would rather. Here is the Λ function associated with the above Λ.","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function ∇Λ(A, Ψ, Φ)\n  \n  ψ = Ψ[1] # no spatial derivatice\n  ψ_x = Ψ[2] # first order spatial derivative in the x direction\n  ψ_xx = Ψ[3] # second order spatial derivative in the x direction\n  ψ_xxx = Ψ[4] # third order spatial derivative in the x direction\n\n  ϕ = Φ[1] # no temporal derivatice\n\n  return [BD.dU(A, ϕ, ψ), BD.dU²(A, ϕ, ψ), BD.dU³(A, ϕ, ψ),\n  BD.dU_x(A, ϕ, ψ_x), BD.dUU_x(A, ϕ, ψ, ψ_x), BD.dU²U_x(A, ϕ, ψ, ψ_x), BD.dU³U_x(A, ϕ, ψ, ψ_x),\n  BD.dU_xx(A, ϕ, ψ_xx), BD.dUU_xx(A, ϕ, ψ, ψ_xx), BD.dU²U_xx(A, ϕ, ψ, ψ_xx), BD.dU³U_xx(A, ϕ, ψ, ψ_xx),\n  BD.dU_xxx(A, ϕ, ψ_xxx), BD.dUU_xxx(A, ϕ, ψ, ψ_xxx), BD.dU²U_xxx(A, ϕ, ψ, ψ_xxx), BD.dU³U_xxx(A, ϕ, ψ, ψ_xxx)]\n\nend","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"In the above function, we have BD defined as","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"using BayesianSVD\nconst BD = BayesianDiscovery","category":"page"},{"location":"featurelibrary/#Writing-your-own-derivative","page":"Feature Library","title":"Writing your own derivative","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"There are a list of derivative functions we included in the gradients.jl file, but there will likely be situations where you want your own function. Here is how they are created and how you might write your own.","category":"page"},{"location":"featurelibrary/#Derivatives-of-polynomials-of-the-process","page":"Feature Library","title":"Derivatives of polynomials of the process","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"The process is defined as u = A * (ϕ  ψ), and so dudA = (ϕ  ψ). Similarly, u^2 = (A * (ϕ  ψ))^2, and so du^2dA = 2 * (A * (ϕ  ψ)) *(ϕ  ψ). Below are the derivatives for feature library functions u, u^2, and u^3.","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function dU(A, ϕ, ψ)\n    (ϕ ⊗ ψ)'\nend\n\nfunction dU²(A, ϕ, ψ)\n    2 .* (A * (ϕ ⊗ ψ)) .*(ϕ ⊗ ψ)'\nend\n\nfunction dU³(A, ϕ, ψ)\n    3 .* (A * (ϕ ⊗ ψ)).^2 .* (ϕ ⊗ ψ)'\nend\n","category":"page"},{"location":"featurelibrary/#Derivatives-of-higher-order-derivatives-of-the-process","page":"Feature Library","title":"Derivatives of higher order derivatives of the process","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"To compute derivatives of du_xdA or du_xxdA, note that u_x = A * (ϕ  ψ_x), and so du_xdA = (ϕ  ψ_x) and similary du_xxdA = (ϕ  ψ_xx). Below are the equivalent functions.","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function dU_x(A, ϕ, ψ_x)\n    (ϕ ⊗ ψ_x)'\nend\n\nfunction dU_xx(A, ϕ, ψ_xx)\n    (ϕ ⊗ ψ_xx)'\nend","category":"page"},{"location":"featurelibrary/#Derivatives-of-higher-order-interaction-of-the-process","page":"Feature Library","title":"Derivatives of higher order interaction of the process","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"For feature library functions like u * u_x, we have u * u_x = (A * (ϕ  ψ)) * (A * (ϕ  ψ_x)), and so duu_xdA = (((ϕ  ψ)) * (A * (ϕ  ψ_x))) + ((A * (ϕ  ψ)) * ((ϕ  ψ_x))). In this manner, you can create much more complicated function interactions and derivatives. Here, we have the equivalent function for duu_xdA, but if you want more examples on how to make your own function, look at the gradients.jl file.","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function dUU_x(A, ϕ, ψ, ψ_x)\n    (((ϕ ⊗ ψ)') .* (A * (ϕ ⊗ ψ_x))) + ((A * (ϕ ⊗ ψ)) .* ((ϕ ⊗ ψ_x)'))\nend","category":"page"},{"location":"reactiondiffusion/","page":"Reaction Diffusion","title":"Reaction Diffusion","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"reactiondiffusion/#Reaction-Diffusion-Example","page":"Reaction Diffusion","title":"Reaction Diffusion Example","text":"","category":"section"},{"location":"reactiondiffusion/","page":"Reaction Diffusion","title":"Reaction Diffusion","text":"#TODO: Finish example docs","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"#BayesianDiscovery","page":"Home","title":"BayesianDiscovery","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is the documentation for BayesianDiscovery, a Julia package compiled for xxxx. To install the package, clone the repository from GitHub and place it in your /.julia/dev/ folder, navigate to the folder, and run ","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> ] dev .","category":"page"},{"location":"","page":"Home","title":"Home","text":"This will make the package callable via the using BayesianDiscovery command.","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"burgers/#Burgers-Example","page":"Burgers Equation","title":"Burgers Example","text":"","category":"section"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"using BayesianDiscovery\nconst BD = BayesianDiscovery\nusing Distances, Plots, Random, Distributions, LinearAlgebra\nusing FFTW\nusing OrdinaryDiffEq\nusing Plots\nusing Random, Distributions\nusing Kronecker\nusing JLD2\n\n@load \"/Users/JSNorth/.julia/dev/BayesianDiscovery/docs/src/savedRuns/BurgersRun.jld2\" model pars posterior\n","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"Start by simulating and visualizing some data from the Burgers equation which is given by ","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"    u_t(st) = -u(st)u_x(st) + nu u_xx(st)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"where u(st) is the speed of the fluid at location s = (x) and time t and nu is the viscosity of the fluid.","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"function burgers_pde(u, p, t)\n    k,nu = p\n    deriv = -u .* FFTW.ifft(1im .* k .* FFTW.fft(u)) + nu*FFTW.ifft(-k .^2 .* FFTW.fft(u))\n    return real(deriv)\nend\n\n\nfunction burgers(;nx = 256, nt = 101, Lx = 8, Lt = 10.0, nu=0.1)\n\n    # Set up grid\n    x = range(-Lx, Lx, nx+1)[1:(end-1)]\n    dx = x[2] - x[1]\n    t = range(0, Lt, nt)\n    dt = t[2]-t[1]\n    k = 2*pi*FFTW.fftfreq(nx, nx*dx)\n\n    # Initial condition\n    u0 = exp.(-(x.+2).^2)\n\n\n    # Solve\n    p = (k, nu)\n    tspan = (0.0, Lt)\n    prob = OrdinaryDiffEq.ODEProblem(burgers_pde, u0, tspan, p)\n    sol = OrdinaryDiffEq.solve(prob, dt = dt, OrdinaryDiffEq.Tsit5(), saveat = t)\n\n    return reduce(hcat, sol.u), Vector(x), sol.t\n    \nend\n\n\nU, x, Time = burgers()\nPlots.contourf(Time, x, U, c=:oxy)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"Next, we add reshape the solution surface U to be a space times time times process array (here 256 times 101 times 1) and add noise.","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"Random.seed!(1)\nY = reshape(real.(U), 256, 101, 1)\nZ = Y + 0.02 * std(Y) .* rand(Normal(), 256, 101, 1)\nPlots.contourf(Time, x, Z[:,:,1], c=:oxy)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"The MCMC sampler function, DEtection(), takes a lot of parameters (TO DO: break apart the function call into smaller chuncks). See ?DEtection() for the argument requirements. Additionally, we need to define the feature library and the derivative of the feature library (see Feature Library).","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"SpaceStep = [x]\nTimeStep = Time\nνS = 50 # number of space basis functions\nνT = 20 # number of time basis functions\nbatchSpace = 10\nbatchTime = 10\nlearning_rate = 1e-4\nbeta = 0.9\n\nΛSpaceNames = [\"Psi\", \"Psi_x\", \"Psi_xx\", \"Psi_xxx\"]\nΛTimeNames = [\"Phi\"]\n\n# choose library\nfunction Λ(A, Ψ, Φ)\n    \n  ψ = Ψ[1]\n  ψ_x = Ψ[2]\n  ψ_xx = Ψ[3]\n  ψ_xxx = Ψ[4]\n\n  ϕ = Φ[1]\n\n  u = A * (ϕ ⊗ ψ)'\n  u_x = A * (ϕ ⊗ ψ_x)'\n  u_xx = A * (ϕ ⊗ ψ_xx)'\n  u_xxx = A * (ϕ ⊗ ψ_xxx)'\n\n  return [u, u.^2, u.^3,\n    u_x, u .* u_x, u.^2 .* u_x, u.^3 .* u_x,\n    u_xx, u .* u_xx, u.^2 .* u_xx, u.^3 .* u_xx,\n    u_xxx, u .* u_xxx, u.^2 .* u_xxx, u.^3 .* u_xxx]\n\nend\n\nfunction ∇Λ(A, Ψ, Φ)\n  \n  ψ = Ψ[1]\n  ψ_x = Ψ[2]\n  ψ_xx = Ψ[3]\n  ψ_xxx = Ψ[4]\n\n  ϕ = Φ[1]\n\n  return [BD.dU(A, ϕ, ψ), BD.dU²(A, ϕ, ψ), BD.dU³(A, ϕ, ψ),\n  BD.dU_x(A, ϕ, ψ_x), BD.dUU_x(A, ϕ, ψ, ψ_x), BD.dU²U_x(A, ϕ, ψ, ψ_x), BD.dU³U_x(A, ϕ, ψ, ψ_x),\n  BD.dU_xx(A, ϕ, ψ_xx), BD.dUU_xx(A, ϕ, ψ, ψ_xx), BD.dU²U_xx(A, ϕ, ψ, ψ_xx), BD.dU³U_xx(A, ϕ, ψ, ψ_xx),\n  BD.dU_xxx(A, ϕ, ψ_xxx), BD.dUU_xxx(A, ϕ, ψ, ψ_xxx), BD.dU²U_xxx(A, ϕ, ψ, ψ_xxx), BD.dU³U_xxx(A, ϕ, ψ, ψ_xxx)]\n\nend","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"To run the model we use the DEtection() function which returns the model, pars, and posterior structures which can be passed into various functions to investigate the output. For example, the print_equation() function will return the \"discovered\" PDE given a cutoff probability (cutoff_prob) value. <!– ```@example –>","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"model, pars, posterior = DEtection(Z, SpaceStep, TimeStep, νS, νT, batchSpace, batchTime, learning_rate, beta, Λ, ∇Λ, ΛSpaceNames, ΛTimeNames, nits = 1000, burnin = 500)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"We can then print the mean estimate along with the 95% highest posterior density (HPD) intervals.","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"print_equation([\"uₜ\"], model, pars, posterior, cutoff_prob=0.5)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"We see the true equation","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"    u_t = -u(st)u_x + 01 u_xx","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"is covered by the interval!","category":"page"}]
}
