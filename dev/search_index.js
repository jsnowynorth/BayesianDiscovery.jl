var documenterSearchIndex = {"docs":
[{"location":"api/","page":"API","title":"API","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [BayesianDiscovery]","category":"page"},{"location":"api/#BayesianDiscovery.BayesianDiscovery","page":"API","title":"BayesianDiscovery.BayesianDiscovery","text":"BayesianDiscovery\n\nHere is my package.\n\n\n\n\n\n","category":"module"},{"location":"api/#BayesianDiscovery.Posterior","page":"API","title":"BayesianDiscovery.Posterior","text":"Posterior Struct\n\nInitiates a structure of class Posterior to hold posterior samples\n\nArguments\n\n\n\n\n\n","category":"type"},{"location":"api/#BayesianDiscovery.DEtection-Tuple{Array{Float64, 3}, Vector, Vector, Int64, Int64, Int64, Int64, Float64, Float64, Function, Function, Vector{String}, Vector{String}}","page":"API","title":"BayesianDiscovery.DEtection","text":"DEtection(Y, SpaceStep, TimeStep, Î½S, Î½T, bufferSpace, bufferTime, batchSpace, batchTime, learning_rate, v0, v1, Î›, Î›names)\n\nDEtection sampler function. Can accept missing values in the input data argument. Returns the model, parameters, and posterior values. The model are the model settings. The parameters are the final value of the parameters in from the sampler. The posterior are the saved posterior values.\n\nConsider the function U_t = M(U U_x U_y U_xy ). DEtection() is used to determine M given a library of potential values, Î›(U, âˆ‚U), to search over.  Within the function, partial derivatives are denoted as Î”U_t Î”U_x Î”U_y Î”U_xx  Î”U_xy , so a potential function could be\n\nfunction Î›(U, âˆ‚U){\n  u = U[1]\n  u_x = âˆ‚U[1]\n  u_y = âˆ‚U[2]\n\n  return [u, u_x, u_y, u*u_x, u*u_y]\n}\n\nTo make the function identify the correct partial derivatives, the argument that are passed into âˆ‚U, Î›names, are required. For the example above, Î›names = [Î”U_x, Î”U_y] because the function Î› uses the partial derivatives U_x and U_t.\n\nIf you want to add covariates to the function, a possible Î›(U, âˆ‚U, X) is\n\nfunction Î›(U, âˆ‚U, X){\n  u = U[1]\n  u_x = âˆ‚U[1]\n  u_y = âˆ‚U[2]\n  x1 = X[1]\n  x2 = X[2]\n\n  return [u, u_x, u_y, u*u_x, u*u_y, x1, x2, u*x1, u_x*x2]\n}\n\nwhere Î›names = [Î”U_x, Î”U_y].\n\nRequired Arguments (in order)\n\nY: Input data. Needs to be Array{Float64, 3} or Array{Union{Missing, Float64}, 3} where the dimensions are Space, Time, Components\nSpaceStep: of type StepRangeLen (range function). For example, range(-1, 1, step = 0.1) for 1 dimension and [range(-1, 1, step = 0.1), range(-1, 1, step = 0.1)] for 2.\nTimeStep: of type StepRangeLen (range function). For example, range(-1, 1, step = 0.1).\nÎ½S::Int or Î½S::Vector{Int}: Number of spatial basis functions. \nÎ½T::Int: Number of temporal basis functions\nbatchSpace::Int: \nbatchTime::Int: \nlearning_rate::Float64: \nv0::Float64: \nv1::Float64: \nÎ›::Function: \nÎ›names::Vector{String}: \n\nOptional Arguments\n\nresponse = \"Î”Ut\": Order of the temporal derivative (default first order). Use \"Î”Utt\" for second and so on.\ndegree = 4: Degree of the B-spline. Must be at least one order higher than the highest order partial derivative.\norderTime = 1: Order of the highest order temporal derivative (default âˆ‚U_t)\norderSpace = 3: Order of the highest order spatial derivative (default âˆ‚Uxxx and âˆ‚Uyyy)\nlatent_dim = size(Y, 3): Dimension of the latent space. Default is same as data dimension.\ncovariates = nothing: Additional covariates.\nnits = 2000: Number of samples for the Gibbs sampler.\nburnin = nits / 2: Number of samples to discard as burnin (default is half of nits).\nlearning_rate_end = learning_rate: End learning rate (default is same as initial learning rate).\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.bspline-NTuple{4, Any}","page":"API","title":"BayesianDiscovery.bspline","text":"bspline(x, knot_locs, degree, derivative)\n\nCreates a matrix of B-Splines evaluated at each x with specified knot locations and degree. Dimension is (length(x), length(xknotlocs)). Returns the basis matrix and the derivative of the basis matrix.\n\nArguments\n\nx: data\nknot_locs: knot locations\ndegree: degree of the B-Spline\nderivative: order of the derivative for Psi_x\n\nExamples\n\nx = 1:1:30\nknot_locs = 5:5:25\ndegree = 3\nderivative = 1\n\nPsi, Psi_x = bspline(x, knot_locs, degree, derivative)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.create_pars-Tuple{Array{Float64, 3}, Vector, Vector, Vector{Int64}, Int64, Int64, Int64, Vector{Float64}, Float64, Function, Function, Vector{String}, Vector{String}}","page":"API","title":"BayesianDiscovery.create_pars","text":"create_pars()\n\nConstructs the parameter and model classes.\n\nArguments\n\nY::Array{Float64, 3}: Space x Time x Component data array\nSpaceStep::Vector{StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}}}: Vector of spatial locations [x, y]\nTimeStep::StepRangeLen{Float64, Base.TwicePrecision{Float64}, Base.TwicePrecision{Float64}}: Time samples\nÎ½S::Vector{Int32}: number of spatial basis functions [x, y]\nÎ½T::Int: number of temporal basis functions\nbufferSpace::Vector{Int}: spatial buffer [x, y]\nbufferTime::Int: temporal buffer\nbatchSpace::Int: batch size for space [x, y]\nbatchTime::Int: batch size for time\nlearning_rate::Float64: learning rate\nv0::Float64: ssvs not included variance\nv1::Float64: ssvs included variance\nÎ›::Function: function library\nÎ›names::Vector{String}: names of arguments in function library\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.fold3-NTuple{4, Any}","page":"API","title":"BayesianDiscovery.fold3","text":"fold3(Y)\n\nUsed to construct a tensor from the mode-3 matrix Y.\n\nExamples\n\nY3 = unfold3(Y) I = size(Y, 1) J = size(Y, 2) K = size(Y, 3)\n\nY = fold3(Y3, I, J, K)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.spatial_bspline-NTuple{7, Any}","page":"API","title":"BayesianDiscovery.spatial_bspline","text":"spatial_bspline(x, y, x_knot_locs, y_knot_locs, degree)\n\nCreates a matrix of B-Splines evaluated at each x and y with specified knot locations and degree. Dimension is (length(x)length(y), length(xknotlocs)length(yknotlocs)). Returns the basis matrix and the derivative of the basis matrix.\n\nArguments\n\nx: data in the x direction\ny: data in the x direction\nxknotlocs: knot locations for x\nyknotlocs: knot locations for y\ndegree: degree of the B-Spline\n\nExamples\n\nx = 1:1:30\ny = 1:1:30\nx_knot_locs = 5:5:25\ny_knot_locs = 5:5:25\ndegree = 3\n\nPsi, Psi_x, Psi_y, Psi_xy = spatial_bspline(x, y, x_knot_locs, y_knot_locs, degree)\n\n# plot the functions\nPlots.pyplot()\ncontour(x, y, reshape(Psi, length(x), length(y)), fill = true)\ncontour(x, y, reshape(Psi_x, length(x), length(y)), fill = true)\ncontour(x, y, reshape(Psi_y, length(x), length(y)), fill = true)\ncontour(x, y, reshape(Psi_xy, length(x), length(y)), fill = true)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.tensor_mult-NTuple{4, Any}","page":"API","title":"BayesianDiscovery.tensor_mult","text":"tensor_mult(G, A, B, C)\n\nUsed to multiply a tensor G âˆˆ R(I1, I2, I3) with matrices A âˆˆ R(P, I1), B âˆˆ R(Q, I2), C âˆˆ R(R, I3)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.unfold3-Tuple{Array{Float64, 3}}","page":"API","title":"BayesianDiscovery.unfold3","text":"unfold3(Y)\n\nUsed to get the mode-3 matrix of the tensor Y.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.update_A!-Tuple{Any, Any}","page":"API","title":"BayesianDiscovery.update_A!","text":"update_A!(pars)\n\nUsed within DEtection() function with a spike-and-slab prior. Updates ð€ with the elastic net prior (Li 2010) from\n\nð³(ð¬ t) = â„‹(ð¬t) ðš¯ ð€ (ð›—phi_t^(0)(t)  ð›™(ð¬)) + ð›œ(ð¬ t)\n\nðš¯ ð€ (ð›—_t^(i)(t)  g(ð›™(ð¬))) = ðŒ ðŸ() + ð›ˆ(ð¬ t) \n\np(ð€)  exp-Î»â‚ð€â‚ - Î»â‚‚ð€â‚‚Â²\n\nusing Stochastic Gradient Desent with a Constant Learning Rate (Mandt 2016). Î»â‚ and Î»â‚‚ are set to 1/100.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.update_M!-Tuple{Any, Any}","page":"API","title":"BayesianDiscovery.update_M!","text":"update_M!(pars)\n\nUsed within DEtection() function with a spike-and-slab prior. Updates ðŒ and ðšºáµ¤ from \n\nðš¯ ð€ (ð›—_t^(i)(t)  g(ð›™(ð¬))) = ðŒ ðŸ() + ð›ˆ(ð¬ t) \n\nwhere ð›ˆ(ð¬ t)  N_N(0 ðšºáµ¤)and ðšºáµ¤ = diag(ÏƒÂ²áµ¤1  ÏƒÂ²áµ¤N)\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.update_gamma!-Tuple{Any, Any}","page":"API","title":"BayesianDiscovery.update_gamma!","text":"update_gamma!(pars)\n\nUsed within DEtection() function with a spike-and-slab prior. Updates gamma and pi from the spike-and-slab prior from\n\np(ðŒ ð›„) = p-slab(ðŒ áµ§)â±¼ p-spike(Mâ±¼)\n\nwhere p(Î³â±¼ = 1 Ï€) = Ï€, Ï€  â„¬(a b), p-slab(ðŒ áµ§) = N(ðŒ áµ§ ðšáµ§ ðšºáµ¤ð€áµ§), and ð€áµ§ = cðˆ.\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.update_Î£Z!-Tuple{Any, Any}","page":"API","title":"BayesianDiscovery.update_Î£Z!","text":"update_Î£Z!(pars)\n\nUsed within DEtection() function with a spike-and-slab prior. Updates ðšºz from \n\nð³(ð¬ t) = â„‹(ð¬t) ðš¯ ð€ (ð›—phi_t^(0)(t)  ð›™(ð¬)) + ð›œ(ð¬ t)\n\nwhere ð›œ(ð¬ t)  N_N(0 ðšºz), ðšºz = diag(ÏƒÂ²z1  ÏƒÂ²zm), and ÏƒÂ²z  Half-t().\n\n\n\n\n\n","category":"method"},{"location":"api/#BayesianDiscovery.Î”L-Tuple{Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Any, Matrix{Float64}}","page":"API","title":"BayesianDiscovery.Î”L","text":"Î”L(z, H, Ïˆ, gÏˆ, Ï•, Ï•_t, Î˜, Î£Zinv, Î£Uinv, A, M, fcurr, fprime)\n\nUsed within DEtection() function. Calculates the gradient of the log likelihood.\n\n\n\n\n\n","category":"method"},{"location":"heat/","page":"Heat Equation","title":"Heat Equation","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"heat/#Heat-Example","page":"Heat Equation","title":"Heat Example","text":"","category":"section"},{"location":"heat/","page":"Heat Equation","title":"Heat Equation","text":"#TODO: Finish example docs","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"featurelibrary/#Feature-Library-Inputs","page":"Feature Library","title":"Feature Library Inputs","text":"","category":"section"},{"location":"featurelibrary/#Feature-Library","page":"Feature Library","title":"Feature Library","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"Properly defining the feature library to work with the DEtection() function is challenging. There are two input functions for the feature library, Î› and âˆ‡Î›. Î› is the actual library and âˆ‡Î› is the derivative of Î› (note, this could be replaced with automatic differention, but AD is slow in this case). Each function must take 3 parameters, A Î¨ Î¦ where A is a matrix of the basis coefficients, Î¨ = Ïˆ Ïˆ_x Ïˆ_xx  is a vector of spatial basis functions and Î¦ = Ï• Ï•_t Ï•_tt  is a vector of temporal basis functions. The surface and its derivatives are then reconstructed as u = A * (Ï•  Ïˆ), u_x = A * (Ï•  Ïˆ_x), u_t = A * (Ï•_t  Ïˆ), and so on, within the function. The first function, Î›, must return a vector of u and all of the functions in the feature library such as,","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function Î›(A, Î¨, Î¦)\n    \n  Ïˆ = Î¨[1] # no spatial derivatice\n  Ïˆ_x = Î¨[2] # first order spatial derivative in the x direction\n  Ïˆ_xx = Î¨[3] # second order spatial derivative in the x direction\n  Ïˆ_xxx = Î¨[4] # third order spatial derivative in the x direction\n\n  Ï• = Î¦[1] # no temporal derivatice\n\n  u = A * (Ï• âŠ— Ïˆ)' # base process\n  u_x = A * (Ï• âŠ— Ïˆ_x)' # first order spatial derivative of the process in the x direction\n  u_xx = A * (Ï• âŠ— Ïˆ_xx)' # second order spatial derivative of the process in the x direction\n  u_xxx = A * (Ï• âŠ— Ïˆ_xxx)' # third order spatial derivative of the process in the x direction\n\n  return [u, u.^2, u.^3,\n    u_x, u .* u_x, u.^2 .* u_x, u.^3 .* u_x,\n    u_xx, u .* u_xx, u.^2 .* u_xx, u.^3 .* u_xx,\n    u_xxx, u .* u_xxx, u.^2 .* u_xxx, u.^3 .* u_xxx] # this is the feature library\n\nend","category":"page"},{"location":"featurelibrary/#Feature-Library-Derivative","page":"Feature Library","title":"Feature Library Derivative","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"The second function, Î›, is slightly more complicated. It requires the same inputs, however the output is the derivative of the feature library with respect to the matrix A. We have included some helper function, such as BayesianDiscovery.dU(A, Ï•, Ïˆ) or BayesianDiscovery.dU_x(A, Ï•, Ïˆ_x), but you can write your own functions if you would rather. Here is the Î› function associated with the above Î›.","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function âˆ‡Î›(A, Î¨, Î¦)\n  \n  Ïˆ = Î¨[1] # no spatial derivatice\n  Ïˆ_x = Î¨[2] # first order spatial derivative in the x direction\n  Ïˆ_xx = Î¨[3] # second order spatial derivative in the x direction\n  Ïˆ_xxx = Î¨[4] # third order spatial derivative in the x direction\n\n  Ï• = Î¦[1] # no temporal derivatice\n\n  return [BD.dU(A, Ï•, Ïˆ), BD.dUÂ²(A, Ï•, Ïˆ), BD.dUÂ³(A, Ï•, Ïˆ),\n  BD.dU_x(A, Ï•, Ïˆ_x), BD.dUU_x(A, Ï•, Ïˆ, Ïˆ_x), BD.dUÂ²U_x(A, Ï•, Ïˆ, Ïˆ_x), BD.dUÂ³U_x(A, Ï•, Ïˆ, Ïˆ_x),\n  BD.dU_xx(A, Ï•, Ïˆ_xx), BD.dUU_xx(A, Ï•, Ïˆ, Ïˆ_xx), BD.dUÂ²U_xx(A, Ï•, Ïˆ, Ïˆ_xx), BD.dUÂ³U_xx(A, Ï•, Ïˆ, Ïˆ_xx),\n  BD.dU_xxx(A, Ï•, Ïˆ_xxx), BD.dUU_xxx(A, Ï•, Ïˆ, Ïˆ_xxx), BD.dUÂ²U_xxx(A, Ï•, Ïˆ, Ïˆ_xxx), BD.dUÂ³U_xxx(A, Ï•, Ïˆ, Ïˆ_xxx)]\n\nend","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"In the above function, we have BD defined as","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"using BayesianSVD\nconst BD = BayesianDiscovery","category":"page"},{"location":"featurelibrary/#Writing-your-own-derivative","page":"Feature Library","title":"Writing your own derivative","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"There are a list of derivative functions we included in the gradients.jl file, but there will likely be situations where you want your own function. Here is how they are created and how you might write your own.","category":"page"},{"location":"featurelibrary/#Derivatives-of-polynomials-of-the-process","page":"Feature Library","title":"Derivatives of polynomials of the process","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"The process is defined as u = A * (Ï•  Ïˆ), and so dudA = (Ï•  Ïˆ). Similarly, u^2 = (A * (Ï•  Ïˆ))^2, and so du^2dA = 2 * (A * (Ï•  Ïˆ)) *(Ï•  Ïˆ). Below are the derivatives for feature library functions u, u^2, and u^3.","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function dU(A, Ï•, Ïˆ)\n    (Ï• âŠ— Ïˆ)'\nend\n\nfunction dUÂ²(A, Ï•, Ïˆ)\n    2 .* (A * (Ï• âŠ— Ïˆ)) .*(Ï• âŠ— Ïˆ)'\nend\n\nfunction dUÂ³(A, Ï•, Ïˆ)\n    3 .* (A * (Ï• âŠ— Ïˆ)).^2 .* (Ï• âŠ— Ïˆ)'\nend\n","category":"page"},{"location":"featurelibrary/#Derivatives-of-higher-order-derivatives-of-the-process","page":"Feature Library","title":"Derivatives of higher order derivatives of the process","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"To compute derivatives of du_xdA or du_xxdA, note that u_x = A * (Ï•  Ïˆ_x), and so du_xdA = (Ï•  Ïˆ_x) and similary du_xxdA = (Ï•  Ïˆ_xx). Below are the equivalent functions.","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function dU_x(A, Ï•, Ïˆ_x)\n    (Ï• âŠ— Ïˆ_x)'\nend\n\nfunction dU_xx(A, Ï•, Ïˆ_xx)\n    (Ï• âŠ— Ïˆ_xx)'\nend","category":"page"},{"location":"featurelibrary/#Derivatives-of-higher-order-interaction-of-the-process","page":"Feature Library","title":"Derivatives of higher order interaction of the process","text":"","category":"section"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"For feature library functions like u * u_x, we have u * u_x = (A * (Ï•  Ïˆ)) * (A * (Ï•  Ïˆ_x)), and so duu_xdA = (((Ï•  Ïˆ)) * (A * (Ï•  Ïˆ_x))) + ((A * (Ï•  Ïˆ)) * ((Ï•  Ïˆ_x))). In this manner, you can create much more complicated function interactions and derivatives. Here, we have the equivalent function for duu_xdA, but if you want more examples on how to make your own function, look at the gradients.jl file.","category":"page"},{"location":"featurelibrary/","page":"Feature Library","title":"Feature Library","text":"function dUU_x(A, Ï•, Ïˆ, Ïˆ_x)\n    (((Ï• âŠ— Ïˆ)') .* (A * (Ï• âŠ— Ïˆ_x))) + ((A * (Ï• âŠ— Ïˆ)) .* ((Ï• âŠ— Ïˆ_x)'))\nend","category":"page"},{"location":"reactiondiffusion/","page":"Reaction Diffusion","title":"Reaction Diffusion","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"reactiondiffusion/#Reaction-Diffusion-Example","page":"Reaction Diffusion","title":"Reaction Diffusion Example","text":"","category":"section"},{"location":"reactiondiffusion/","page":"Reaction Diffusion","title":"Reaction Diffusion","text":"#TODO: Finish example docs","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"#BayesianDiscovery","page":"Home","title":"BayesianDiscovery","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is the documentation for BayesianDiscovery, a Julia package compiled for xxxx. To install the package, clone the repository from GitHub and place it in your /.julia/dev/ folder, navigate to the folder, and run ","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> ] dev .","category":"page"},{"location":"","page":"Home","title":"Home","text":"This will make the package callable via the using BayesianDiscovery command.","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"CurrentModule = BayesianDiscovery","category":"page"},{"location":"burgers/#Burgers-Example","page":"Burgers Equation","title":"Burgers Example","text":"","category":"section"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"using BayesianDiscovery\nconst BD = BayesianDiscovery\nusing Distances, Plots, Random, Distributions, LinearAlgebra\nusing FFTW\nusing OrdinaryDiffEq\nusing Plots\nusing Random, Distributions\nusing Kronecker\nusing JLD2\n\n@load \"/Users/JSNorth/.julia/dev/BayesianDiscovery/docs/src/savedRuns/BurgersRun.jld2\" model pars posterior\n","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"Start by simulating and visualizing some data from the Burgers equation which is given by ","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"    u_t(st) = -u(st)u_x(st) + nu u_xx(st)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"where u(st) is the speed of the fluid at location s = (x) and time t and nu is the viscosity of the fluid.","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"function burgers_pde(u, p, t)\n    k,nu = p\n    deriv = -u .* FFTW.ifft(1im .* k .* FFTW.fft(u)) + nu*FFTW.ifft(-k .^2 .* FFTW.fft(u))\n    return real(deriv)\nend\n\n\nfunction burgers(;nx = 256, nt = 101, Lx = 8, Lt = 10.0, nu=0.1)\n\n    # Set up grid\n    x = range(-Lx, Lx, nx+1)[1:(end-1)]\n    dx = x[2] - x[1]\n    t = range(0, Lt, nt)\n    dt = t[2]-t[1]\n    k = 2*pi*FFTW.fftfreq(nx, nx*dx)\n\n    # Initial condition\n    u0 = exp.(-(x.+2).^2)\n\n\n    # Solve\n    p = (k, nu)\n    tspan = (0.0, Lt)\n    prob = OrdinaryDiffEq.ODEProblem(burgers_pde, u0, tspan, p)\n    sol = OrdinaryDiffEq.solve(prob, dt = dt, OrdinaryDiffEq.Tsit5(), saveat = t)\n\n    return reduce(hcat, sol.u), Vector(x), sol.t\n    \nend\n\n\nU, x, Time = burgers()\nPlots.contourf(Time, x, U, c=:oxy)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"Next, we add reshape the solution surface U to be a space times time times process array (here 256 times 101 times 1) and add noise.","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"Random.seed!(1)\nY = reshape(real.(U), 256, 101, 1)\nZ = Y + 0.02 * std(Y) .* rand(Normal(), 256, 101, 1)\nPlots.contourf(Time, x, Z[:,:,1], c=:oxy)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"The MCMC sampler function, DEtection(), takes a lot of parameters (TO DO: break apart the function call into smaller chuncks). See ?DEtection() for the argument requirements. Additionally, we need to define the feature library and the derivative of the feature library (see Feature Library).","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"SpaceStep = [x]\nTimeStep = Time\nÎ½S = 50 # number of space basis functions\nÎ½T = 20 # number of time basis functions\nbatchSpace = 10\nbatchTime = 10\nlearning_rate = 1e-4\nbeta = 0.9\n\nÎ›SpaceNames = [\"Psi\", \"Psi_x\", \"Psi_xx\", \"Psi_xxx\"]\nÎ›TimeNames = [\"Phi\"]\n\n# choose library\nfunction Î›(A, Î¨, Î¦)\n    \n  Ïˆ = Î¨[1]\n  Ïˆ_x = Î¨[2]\n  Ïˆ_xx = Î¨[3]\n  Ïˆ_xxx = Î¨[4]\n\n  Ï• = Î¦[1]\n\n  u = A * (Ï• âŠ— Ïˆ)'\n  u_x = A * (Ï• âŠ— Ïˆ_x)'\n  u_xx = A * (Ï• âŠ— Ïˆ_xx)'\n  u_xxx = A * (Ï• âŠ— Ïˆ_xxx)'\n\n  return [u, u.^2, u.^3,\n    u_x, u .* u_x, u.^2 .* u_x, u.^3 .* u_x,\n    u_xx, u .* u_xx, u.^2 .* u_xx, u.^3 .* u_xx,\n    u_xxx, u .* u_xxx, u.^2 .* u_xxx, u.^3 .* u_xxx]\n\nend\n\nfunction âˆ‡Î›(A, Î¨, Î¦)\n  \n  Ïˆ = Î¨[1]\n  Ïˆ_x = Î¨[2]\n  Ïˆ_xx = Î¨[3]\n  Ïˆ_xxx = Î¨[4]\n\n  Ï• = Î¦[1]\n\n  return [BD.dU(A, Ï•, Ïˆ), BD.dUÂ²(A, Ï•, Ïˆ), BD.dUÂ³(A, Ï•, Ïˆ),\n  BD.dU_x(A, Ï•, Ïˆ_x), BD.dUU_x(A, Ï•, Ïˆ, Ïˆ_x), BD.dUÂ²U_x(A, Ï•, Ïˆ, Ïˆ_x), BD.dUÂ³U_x(A, Ï•, Ïˆ, Ïˆ_x),\n  BD.dU_xx(A, Ï•, Ïˆ_xx), BD.dUU_xx(A, Ï•, Ïˆ, Ïˆ_xx), BD.dUÂ²U_xx(A, Ï•, Ïˆ, Ïˆ_xx), BD.dUÂ³U_xx(A, Ï•, Ïˆ, Ïˆ_xx),\n  BD.dU_xxx(A, Ï•, Ïˆ_xxx), BD.dUU_xxx(A, Ï•, Ïˆ, Ïˆ_xxx), BD.dUÂ²U_xxx(A, Ï•, Ïˆ, Ïˆ_xxx), BD.dUÂ³U_xxx(A, Ï•, Ïˆ, Ïˆ_xxx)]\n\nend","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"To run the model we use the DEtection() function which returns the model, pars, and posterior structures which can be passed into various functions to investigate the output. For example, the print_equation() function will return the \"discovered\" PDE given a cutoff probability (cutoff_prob) value. <!â€“ ```@example â€“>","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"model, pars, posterior = DEtection(Z, SpaceStep, TimeStep, Î½S, Î½T, batchSpace, batchTime, learning_rate, beta, Î›, âˆ‡Î›, Î›SpaceNames, Î›TimeNames, nits = 1000, burnin = 500)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"We can then print the mean estimate along with the 95% highest posterior density (HPD) intervals.","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"print_equation([\"uâ‚œ\"], model, pars, posterior, cutoff_prob=0.5)","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"We see the true equation","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"    u_t = -u(st)u_x + 01 u_xx","category":"page"},{"location":"burgers/","page":"Burgers Equation","title":"Burgers Equation","text":"is covered by the interval!","category":"page"}]
}
